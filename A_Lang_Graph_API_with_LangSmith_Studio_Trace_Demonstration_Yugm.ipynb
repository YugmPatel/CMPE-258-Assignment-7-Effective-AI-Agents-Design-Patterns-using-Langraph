{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge0NPUv_CWtK"
      },
      "source": [
        "# ðŸ§  LangGraph Agent Patterns â€“ Building Effective Agents\n",
        "\n",
        "This Colab notebook demonstrates **common agent design patterns** based on the *\"Building Effective Agents\"* guide, using the **LangGraph** framework.\n",
        "\n",
        "We'll explore and implement the following agent types:\n",
        "\n",
        "### ðŸ¤– Key Patterns:\n",
        "\n",
        "1. **Memory-Based Agent**  \n",
        "   - Maintains context and history to make more coherent, stateful decisions.\n",
        "\n",
        "2. **Tool-Using Agent**  \n",
        "   - Calls external tools/APIs dynamically to enhance its reasoning or capabilities.\n",
        "\n",
        "3. **Multi-Agent Collaboration**  \n",
        "   - Combines specialized agents working together in a shared workflow or dialogue.\n",
        "\n",
        "4. **Planning Agent**  \n",
        "   - Uses planning steps to break down complex tasks into sub-goals and executes them iteratively.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ› ï¸ Technologies Used:\n",
        "\n",
        "- **LangGraph** for defining agent workflows and logic flows\n",
        "- **LangSmith** for tracing, debugging, and observability\n",
        "- **Gemini API (Google)** for LLM interaction (Free tier for demo)\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸŽ¯ Goal:\n",
        "\n",
        "Build flexible, robust, and traceable agents with LangGraph, showcasing how modern agentic architectures can be implemented in a modular, debuggable way.\n",
        "\n",
        "âœ… By the end, you'll understand how to construct and connect agent components for real-world AI applications.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required dependencies\n",
        "!pip install -q langgraph langsmith langchain langchain-google-genai langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hpr64ACoj6A2",
        "outputId": "3eb3b975-ca65-4299-b9d4-4d60b27a6e73"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m151.2/151.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BtTW4eGICVZ6"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import json\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = 'AIzaSyCUwLr2SzPYQOfcgZVrLlMo2p1pZzcPcaU'\n",
        "\n",
        "# Initialize LLM with Gemini\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    temperature=0.7,\n",
        "    google_api_key=GOOGLE_API_KEY\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkIoSnwmCe-c"
      },
      "source": [
        "## ðŸ§  1. Memory-Based Agent Implementation\n",
        "\n",
        "In this section, we implement a **Memory-Based Agent** using **LangGraph**, designed to maintain **context and conversation history** across multiple user interactions.\n",
        "\n",
        "### ðŸ§¾ Key Features:\n",
        "\n",
        "- **Persistent Memory**  \n",
        "  Stores conversation history using LangGraph's **checkpointing** mechanism.\n",
        "  \n",
        "- **Context-Aware Responses**  \n",
        "  The agent uses historical messages to generate relevant, coherent replies.\n",
        "\n",
        "- **State Management with `MemorySaver`**  \n",
        "  Automatically handles storing and retrieving the agent's internal state.\n",
        "\n",
        "- **Powered by Gemini API (Free Tier)**  \n",
        "  Google's Gemini model serves as the LLM backend for generating responses.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ§  Why Use a Memory-Based Agent?\n",
        "\n",
        "- Essential for **multi-turn conversations**\n",
        "- Enables **personalization**, continuity, and deeper reasoning\n",
        "- Simulates real-world agent behavior (e.g., customer support, tutoring)\n",
        "\n",
        "âœ… This setup ensures the agent **remembers what was said before**, providing a more natural and intelligent user experience.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOzvkAKPCbTD",
        "outputId": "73c52473-237c-4747-c7b9-bf0910f3eec8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent: That's a great color! What shade of blue do you like best?\n",
            "Agent: You already told me! Your favorite color is blue.\n"
          ]
        }
      ],
      "source": [
        "# Create a simple memory-based agent\n",
        "from langgraph.graph import StateGraph, END\n",
        "from typing import Annotated, TypedDict\n",
        "import operator\n",
        "\n",
        "# Define the state for our agent\n",
        "class AgentState(TypedDict):\n",
        "   messages: Annotated[list, operator.add]\n",
        "\n",
        "# Create a simple agent that remembers context\n",
        "def memory_agent(state: AgentState):\n",
        "   # Get the last message\n",
        "   last_message = state[\"messages\"][-1]\n",
        "\n",
        "   # Convert messages to string format for context\n",
        "   context_str = \"\\n\".join([f\"{msg.__class__.__name__}: {msg.content}\" for msg in state[\"messages\"]])\n",
        "\n",
        "   # Generate a response based on all previous messages\n",
        "   prompt = f\"Context of conversation:\\n{context_str}\\n\\nCurrent message: {last_message.content}\\n\\nResponse:\"\n",
        "   response = llm.invoke(prompt)\n",
        "\n",
        "   return {\"messages\": [AIMessage(content=response.content)]}\n",
        "\n",
        "# Create the graph\n",
        "memory_graph = StateGraph(AgentState)\n",
        "memory_graph.add_node(\"agent\", memory_agent)\n",
        "memory_graph.set_entry_point(\"agent\")\n",
        "memory_graph.add_edge(\"agent\", END)\n",
        "\n",
        "# Compile with checkpointer for memory\n",
        "memory_checkpointer = MemorySaver()\n",
        "memory_compiled = memory_graph.compile(checkpointer=memory_checkpointer)\n",
        "\n",
        "# Test the memory agent\n",
        "config = {\"configurable\": {\"thread_id\": \"test_thread\"}}\n",
        "result = memory_compiled.invoke(\n",
        "   {\"messages\": [HumanMessage(content=\"My favorite color is blue\")]},\n",
        "   config=config\n",
        ")\n",
        "print(\"Agent:\", result[\"messages\"][-1].content)\n",
        "\n",
        "# Test that it remembers\n",
        "result2 = memory_compiled.invoke(\n",
        "   {\"messages\": [HumanMessage(content=\"What's my favorite color?\")]},\n",
        "   config=config\n",
        ")\n",
        "print(\"Agent:\", result2[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dveGit11EyZr"
      },
      "source": [
        "## ðŸ› ï¸ 2. Tool-Using Agent\n",
        "\n",
        "In this pattern, we implement a **Tool-Using Agent** with LangGraph that can **dynamically invoke external tools** to answer questions or complete tasks.\n",
        "\n",
        "### ðŸ§¾ Key Features:\n",
        "\n",
        "- **Tool Integration with LangGraph**  \n",
        "  The agent is configured to access external APIs or functions (e.g., Wikipedia) as part of its workflow.\n",
        "\n",
        "- **React-Style Reasoning**  \n",
        "  Implements the **Thought â†’ Action â†’ Observation** loop to decide when and how to use tools.\n",
        "\n",
        "- **Dynamic Tool Selection**  \n",
        "  Based on the input query, the agent chooses the most appropriate tool for the task.\n",
        "\n",
        "- **Free Wikipedia API**  \n",
        "  Demonstrates external data retrieval using open, no-auth endpoints.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸŒ Example Use Case:\n",
        "\n",
        "User asks:  \n",
        "> \"Who is the current president of France?\"\n",
        "\n",
        "â†’ Agent identifies this as an **information lookup task**  \n",
        "â†’ Selects the **Wikipedia tool**  \n",
        "â†’ Retrieves relevant summary  \n",
        "â†’ Responds with the answer\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸŽ¯ Why Tool-Using Agents Matter:\n",
        "\n",
        "- Expand the agent's capabilities beyond language generation\n",
        "- Enable **real-time access to up-to-date or specialized knowledge**\n",
        "- Foundation for **autonomous task-solving agents**\n",
        "\n",
        "âœ… This approach models real-world agents that augment reasoning with **retrieval**, **calculation**, or **API access**.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOcKbugNkPhX",
        "outputId": "8ff7110d-d34a-4aea-be49-c3641adbd547"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.4.26)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (4.13.2)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=33f803b05c69df968be7ecaf8da3d3d7a6949a2646b5ffd5709e946b5e309769\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UHmIctdEaNT",
        "outputId": "e19053b3-78f7-4c86-8726-6e3ce7097b19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 389 of the file /usr/local/lib/python3.11/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  lis = BeautifulSoup(html).find_all('li')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool Agent: I searched for 'Newton' and found:\n",
            "\n",
            "Page: Isaac Newton\n",
            "Summary: Sir Isaac Newton (; 4 January [O.S. 25 December] 1643 â€“ 31 March [O.S. 20 March] 1727) was an English polymath active as a mathematician, physicist, astronomer, alchemist, theologian, and author. Newton was a key figure in the Scientific Revolution and the Enlightenment that followed. His book PhilosophiÃ¦ Naturalis Principia Mathematica (Mathematical Principles of Natural Philosophy), first published in 1687, achieved the first great unification in physics and established classical mechanics. Newton also made seminal contributions to optics, and shares credit with German mathematician Gottfried Wilhelm Leibniz for formulating infinitesimal calculus, though he developed calculus years before Leibniz. Newton contributed to and refined the scientific method, and his work is considered the most influential in bringing forth modern science.\n",
            "In the Principia, Newton formulated the laws of motion and universal gravitation that formed the dominant scientific viewpoint for centuries until it was superseded by the theory of relativity. He used his mathematical description of gravity to derive Kepler's laws of planetary motion, account for tides, the trajectories of comets, the precession of the equinoxes and other phenomena, eradicating doubt about the Solar System's heliocentricity. Newton solved the two-body problem, and introduced the three-body problem. He demonstrated that the motion of objects on Earth and celestial bodies could be accounted for by the same principles. Newton's inference that the Earth is an oblate spheroid was later confirmed by the geodetic measurements of Alexis Clairaut, Charles Marie de La Condamine, and others, convincing most European scientists of the superiority of Newtonian mechanics over earlier systems. He was also the first to calculate the age of Earth by experiment, and described a precursor to the modern wind tunnel.\n",
            "Newton built the first reflecting telescope and developed a sophisticated theory of colour based on the observation that a prism separates white light into the colours of the visible spectrum. His work on light was collected in his book Opticks, published in 1704. He originated prisms as beam expanders and multiple-prism arrays, which would later become integral to the development of tunable lasers. He also anticipated waveâ€“particle duality and was the first to theorize the Goosâ€“HÃ¤nchen effect. He further formulated an empirical law of cooling, which was the first heat transfer formulation and serves as the formal basis of convective heat transfer, made the first theoretical calculation of the speed of sound, and introduced the notions of a Newtonian fluid and a black body. He was also the first to explain the Magnus effect. Furthermore, he made early studies into electricity. In addition to his creation of calculus, Newton's work on mathematics was extensive. He generalized the binomial theorem to any real number, introduced the Puiseux series, was the first to state BÃ©zout's theorem, classified most of the cubic plane curves, contributed to the study of Cremona transformations, developed a method for approximating the roots of a function, and also originated the Newtonâ€“Cotes formulas for numerical integration. He further initiated the field of calculus of variations, devised an early form of regression analysis, and was a pioneer of vector analysis.\n",
            "Newton was a fellow of Trinity College and the second Lucasian Professor of Mathematics at the University of Cambridge; he was appointed at the age of 26. He was a devout but unorthodox Christian who privately rejected the doctrine of the Trinity. He refused to take holy orders in the Church of England, unlike most members of the Cambridge faculty of the day. Beyond his work on the mathematical sciences, Newton dedicated much of his time to the study of alchemy and biblical chronology, but most of his work in those areas remained unpublished until long after his death. Politically and personally tied to the Whi\n",
            "Tool Agent: Why don't scientists trust atoms?\n",
            "\n",
            "Because they make up everything!\n"
          ]
        }
      ],
      "source": [
        "from typing import TypedDict, Annotated\n",
        "import operator\n",
        "\n",
        "# Create Wikipedia tool\n",
        "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
        "\n",
        "# Define tool-using agent state\n",
        "class ToolState(TypedDict):\n",
        "   messages: Annotated[list, operator.add]\n",
        "\n",
        "def tool_agent(state: ToolState):\n",
        "   messages = state[\"messages\"]\n",
        "   last_message = messages[-1]\n",
        "\n",
        "   # Create a simple tool-using agent\n",
        "   if \"search\" in last_message.content.lower() or \"find\" in last_message.content.lower():\n",
        "       # Extract search query\n",
        "       search_query = last_message.content.replace(\"search for\", \"\").replace(\"find\", \"\").strip()\n",
        "\n",
        "       # Use Wikipedia tool\n",
        "       search_result = wikipedia.run(search_query)\n",
        "\n",
        "       response = f\"I searched for '{search_query}' and found:\\n\\n{search_result}\"\n",
        "   else:\n",
        "       # Regular response\n",
        "       response = llm.invoke(last_message.content)\n",
        "       response = response.content\n",
        "\n",
        "   return {\"messages\": [AIMessage(content=response)]}\n",
        "\n",
        "# Create tool agent graph\n",
        "tool_graph = StateGraph(ToolState)\n",
        "tool_graph.add_node(\"agent\", tool_agent)\n",
        "tool_graph.set_entry_point(\"agent\")\n",
        "tool_graph.add_edge(\"agent\", END)\n",
        "\n",
        "# Compile and test\n",
        "tool_compiled = tool_graph.compile()\n",
        "\n",
        "# Test tool usage\n",
        "result = tool_compiled.invoke({\"messages\": [HumanMessage(content=\"search for Newton\")]})\n",
        "print(\"Tool Agent:\", result[\"messages\"][-1].content)\n",
        "\n",
        "# Test normal conversation\n",
        "result2 = tool_compiled.invoke({\"messages\": [HumanMessage(content=\"Tell me a joke\")]})\n",
        "print(\"Tool Agent:\", result2[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCWCMQM7E61h"
      },
      "source": [
        "## ðŸ¤ 3. Multi-Agent Collaboration\n",
        "\n",
        "This pattern demonstrates how **multiple specialized agents** can collaborate to solve complex tasks by **sharing state and delegating responsibilities** using LangGraph.\n",
        "\n",
        "### ðŸ§¾ Key Features:\n",
        "\n",
        "- **Specialized Agents with Defined Roles**  \n",
        "  Each agent focuses on a specific sub-task (e.g., planner, researcher, summarizer, code writer).\n",
        "\n",
        "- **Agent Collaboration Workflow**  \n",
        "  LangGraph orchestrates communication and data flow between agents, managing the sequence and logic.\n",
        "\n",
        "- **Shared State Management**  \n",
        "  Agents update and access a shared memory/state object to maintain consistency throughout the task.\n",
        "\n",
        "- **Task Delegation and Coordination**  \n",
        "  One agent (e.g., a planner) can dynamically delegate sub-tasks to others and collect their outputs for a final result.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ§  Example Workflow:\n",
        "\n",
        "1. **Planner Agent** breaks down a user request:\n",
        "   > \"Write a report about the benefits of AI in education.\"\n",
        "\n",
        "2. **Research Agent** gathers content from external tools (e.g., Wikipedia or Gemini).\n",
        "\n",
        "3. **Writer Agent** composes the final report using the gathered facts.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸŽ¯ Why Multi-Agent Systems Matter:\n",
        "\n",
        "- Enable **modular design** and **scalability**\n",
        "- Allow **parallel problem-solving**\n",
        "- Mimic **real-world team workflows** (e.g., project managers, analysts, writers)\n",
        "\n",
        "âœ… Ideal for complex pipelines like document generation, code analysis, multi-step planning, and more.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiIopRKUE4dg",
        "outputId": "0a9da630-b6ab-40c9-80f1-d0d3900f90c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multi-Agent Result:\n",
            "HumanMessage: research about quantum computing\n",
            "AIMessage: Research findings: Page: Quantum computing\n",
            "Summary: A quantum computer is a computer that exploits quantum mechanical phenomena. On small scales, physical matter exhibits properties of both particles and waves, and quantum computing takes advantage of this behavior using specialized hardware. Classical physics cannot explain the operation of these quantum devices, and a scalable quantum computer could perform some calculations exponentially faster than any modern \"classical\" computer. Theoretically a large-scale quantum computer could break some widely used encryption schemes and aid physicists in performing physical simulations; however, the current state of the art is largely experimental and impractical, with several obstacles to useful applications.\n",
            "The basic unit of information in quantum computing, the qubit (or \"quantum bit\"), serves the same function as the bit in classical computing. However, unlike a classical bit, which can be in one of two states (a binary), a qubit can exist in a superposition of its two \"basis\" states, a state that is in an abstract sense \"between\" the two basis states. When measuring a qubit, the result is a probabilistic output of a classical bit. If a quantum computer manipulates the qubit in a particular way, wave interference effects can amplify the desired measurement results. The design of quantum algorithms involves creating procedures that allow a quantum computer to perform calculations efficiently and quickly.\n",
            "Quantum computers are not yet practical for real-world applications. Physically engineering high-quality qubits has proven to be challenging. If a physical qubit is not sufficiently isolated from its environment, it suffers from quantum decoherence, introducing noise into calculations. National governments have invested heavily in experimental research aimed at developing  scalable qubits with longer coherence times and lower error rates. Example implementations include superconductors (which isolate an electrical current by eliminating electrical resistance) and ion traps (which confine a single atomic particle using electromagnetic fields).\n",
            "In principle, a classical computer can solve the same computational problems as a quantum computer, given enough time. Quantum advantage comes in the form of time complexity rather than computability, and quantum complexity theory shows that some quantum algorithms are exponentially more efficient than the best-known classical algorithms. A large-scale quantum computer could in theory solve computational problems that are not solvable within a reasonable timeframe for a classical computer. This concept of additional ability has been called \"quantum supremacy\". While such claims have drawn significant attention to the discipline, near-term practical use cases remain limited.\n",
            "\n",
            "Page: Timeline of quantum computing and communication\n",
            "Summary: This is a timeline of quantum computing.\n",
            "\n",
            "Page: Superconducting quantum computing\n",
            "Summary: Superconducting quantum computing is a branch of solid state  physics and quantum computing that implements superconducting electronic circuits using superconducting qubits as artificial atoms, or quantum dots. For superconducting qubits, the two logic states are the ground state and the excited state, denoted \n",
            "  \n",
            "    \n",
            "      \n",
            "        \n",
            "          |\n",
            "        \n",
            "        g\n",
            "        âŸ©\n",
            "        \n",
            "           and \n",
            "        \n",
            "        \n",
            "          |\n",
            "        \n",
            "        e\n",
            "        âŸ©\n",
            "      \n",
            "    \n",
            "    {\\displaystyle |g\\rangle {\\text{ and }}|e\\rangle }\n",
            "  \n",
            " respectively. Research in superconducting quantum computing is conducted by companies such as Google, IBM, IMEC, BBN Technologies, Rigetti, and Intel.  Many recently developed QPUs (quantum processing units, or quantum chips) use superconducting architecture.\n",
            "As of May 2016, up to 9 fully controllable qubits are demonstrated in the 1D array, and up to 16 in 2D architecture. In October 2019, the Martinis group, partnered with Google, published an article demonstrating novel quantum supremacy, using a chip composed of\n",
            "AIMessage: Quantum computing leverages quantum mechanics to perform calculations in ways classical computers cannot. Qubits, the basic unit of quantum information, can exist in a superposition of states, enabling exponentially faster calculations for certain problems. While still largely experimental, quantum computers hold the theoretical potential to break encryption and revolutionize fields like physics simulations. Current research focuses on overcoming challenges like quantum decoherence to build scalable and practical qubits using technologies like superconductors and ion traps. Superconducting quantum computing, pursued by companies like Google and IBM, utilizes superconducting circuits as qubits and has demonstrated chips with up to dozens of controllable qubits. While classical computers can theoretically solve the same problems, quantum computers offer a potential \"quantum advantage\" in speed, although practical applications remain limited.\n"
          ]
        }
      ],
      "source": [
        "# Define multi-agent state\n",
        "class MultiAgentState(TypedDict):\n",
        "   messages: Annotated[list, operator.add]\n",
        "   task_type: str\n",
        "   current_agent: str\n",
        "   result: str\n",
        "\n",
        "# Create specialized agents\n",
        "def researcher_agent(state: MultiAgentState):\n",
        "   \"\"\"Researches information using Wikipedia\"\"\"\n",
        "   task = state[\"messages\"][-1].content\n",
        "\n",
        "   if \"research\" in task.lower() or \"find information\" in task.lower():\n",
        "       search_query = task.split(\"about\")[-1].strip() if \"about\" in task else task\n",
        "       research_result = wikipedia.run(search_query)\n",
        "\n",
        "       response = f\"Research findings: {research_result}\"\n",
        "       return {\"messages\": [AIMessage(content=response)], \"current_agent\": \"writer\", \"result\": research_result}\n",
        "\n",
        "   return {\"messages\": [AIMessage(content=\"No research task identified\")], \"current_agent\": \"done\"}\n",
        "\n",
        "def writer_agent(state: MultiAgentState):\n",
        "   \"\"\"Writes content based on research\"\"\"\n",
        "   research_result = state.get(\"result\", \"\")\n",
        "\n",
        "   if research_result:\n",
        "       prompt = f\"Based on this research: {research_result}\\n\\nWrite a brief summary:\"\n",
        "       response = llm.invoke(prompt)\n",
        "       return {\"messages\": [AIMessage(content=response.content)], \"current_agent\": \"done\"}\n",
        "\n",
        "   return {\"messages\": [AIMessage(content=\"No research data to write from\")], \"current_agent\": \"done\"}\n",
        "\n",
        "# Create multi-agent workflow\n",
        "multi_agent_graph = StateGraph(MultiAgentState)\n",
        "multi_agent_graph.add_node(\"researcher\", researcher_agent)\n",
        "multi_agent_graph.add_node(\"writer\", writer_agent)\n",
        "\n",
        "# Set entry point\n",
        "multi_agent_graph.set_entry_point(\"researcher\")\n",
        "\n",
        "# Add conditional edges\n",
        "def router(state: MultiAgentState):\n",
        "   if state[\"current_agent\"] == \"writer\":\n",
        "       return \"writer\"\n",
        "   else:\n",
        "       return END\n",
        "\n",
        "multi_agent_graph.add_conditional_edges(\"researcher\", router, {\"writer\": \"writer\", END: END})\n",
        "multi_agent_graph.add_edge(\"writer\", END)\n",
        "\n",
        "# Compile and test\n",
        "multi_agent = multi_agent_graph.compile()\n",
        "\n",
        "# Test multi-agent collaboration\n",
        "result = multi_agent.invoke({\n",
        "   \"messages\": [HumanMessage(content=\"research about quantum computing\")],\n",
        "   \"task_type\": \"research_and_write\",\n",
        "   \"current_agent\": \"researcher\",\n",
        "   \"result\": \"\"\n",
        "})\n",
        "\n",
        "print(\"Multi-Agent Result:\")\n",
        "for msg in result[\"messages\"]:\n",
        "   print(f\"{msg.__class__.__name__}: {msg.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHWCPft3FVDJ"
      },
      "source": [
        "## ðŸ§­ 4. Planning Agent\n",
        "\n",
        "This pattern demonstrates how to build a **Planning Agent** that can **decompose complex tasks into smaller steps** and **execute them sequentially** using LangGraph.\n",
        "\n",
        "### ðŸ§¾ Key Features:\n",
        "\n",
        "- **Task Decomposition**  \n",
        "  Breaks down a high-level user request into manageable sub-tasks.\n",
        "\n",
        "- **Sequential Execution**  \n",
        "  Follows a structured plan, executing each step in order.\n",
        "\n",
        "- **Step-by-Step Tracking**  \n",
        "  Maintains logs of completed steps, allowing for traceability and debugging.\n",
        "\n",
        "- **Goal-Oriented Behavior**  \n",
        "  Each sub-task moves the agent closer to completing the overall goal.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ§  Example Use Case:\n",
        "\n",
        "User asks:  \n",
        "> \"Write a summary report on the latest AI trends and generate a chart.\"\n",
        "\n",
        "â†’ Planning Agent creates the following plan:\n",
        "1. Research latest AI trends  \n",
        "2. Summarize findings  \n",
        "3. Generate chart (calls a plotting tool)\n",
        "\n",
        "â†’ Then it executes each step, possibly delegating to other agents or tools.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸŽ¯ Why Planning Agents Are Useful:\n",
        "\n",
        "- Handle **multi-step reasoning** and **complex workflows**\n",
        "- Ideal for tasks that require **intermediate results** or **tool chaining**\n",
        "- Foundation for autonomous systems like **taskbots**, **code agents**, and **report generators**\n",
        "\n",
        "âœ… With LangGraph, you can build and visualize the **planning + execution loop**, making it easy to debug and extend.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define planning agent state\n",
        "class PlanningState(TypedDict):\n",
        "   messages: Annotated[list, operator.add]\n",
        "   plan: list\n",
        "   current_step: int\n",
        "   step_results: list"
      ],
      "metadata": {
        "id": "EaP1rTqIkeze"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def planning_agent(state: PlanningState):\n",
        "   \"\"\"Creates a plan for complex tasks\"\"\"\n",
        "   task = state[\"messages\"][-1].content\n",
        "\n",
        "   # Generate a plan\n",
        "   prompt = f\"\"\"Break down this task into 3-5 simple steps: {task}\n",
        "\n",
        "Format your response as a numbered list:\n",
        "1. [step]\n",
        "2. [step]\n",
        "3. [step]\"\"\"\n",
        "\n",
        "   plan_response = llm.invoke(prompt)\n",
        "\n",
        "   # Extract plan steps\n",
        "   plan_text = plan_response.content\n",
        "   steps = []\n",
        "   for line in plan_text.split('\\n'):\n",
        "       if line.strip() and any(line.strip().startswith(str(i)) for i in range(1, 6)):\n",
        "           steps.append(line.strip())\n",
        "\n",
        "   return {\n",
        "       \"messages\": [AIMessage(content=f\"Created plan:\\n{plan_text}\")],\n",
        "       \"plan\": steps,\n",
        "       \"current_step\": 0,\n",
        "       \"step_results\": []\n",
        "   }"
      ],
      "metadata": {
        "id": "0i0-jezokg08"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLS6JdKkFSrM",
        "outputId": "c6bf9ada-925c-40fa-a611-70895c9d779c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Planning Agent Results:\n",
            "\n",
            "HumanMessage: Plan and execute: Create a simple chatbot\n",
            "\n",
            "AIMessage: Created plan:\n",
            "Here's a breakdown of creating a simple chatbot into 3 simple steps:\n",
            "\n",
            "1.  **Choose a Platform & Define Scope:** Select a chatbot platform (e.g., Dialogflow, Rasa, or even a simple Python library like ChatterBot). Define the *specific* task your chatbot will perform (e.g., answering FAQs about a product, scheduling appointments, or telling jokes). Keep the scope very limited for your first chatbot.\n",
            "\n",
            "2.  **Design the Conversation Flow:** Map out the basic conversation flow.  Think about the questions users might ask and the corresponding answers your chatbot should provide. Create a list of intents (what the user *wants* to do) and entities (the *details* the user provides).\n",
            "\n",
            "3.  **Implement & Test:**  Use the chosen platform to implement your conversation flow. Train the chatbot with sample phrases related to each intent. Thoroughly test the chatbot with different user inputs to identify areas for improvement and refine its responses.\n",
            "\n",
            "AIMessage: Executed: 1.  **Choose a Platform & Define Scope:** Select a chatbot platform (e.g., Dialogflow, Rasa, or even a simple Python library like ChatterBot). Define the *specific* task your chatbot will perform (e.g., answering FAQs about a product, scheduling appointments, or telling jokes). Keep the scope very limited for your first chatbot.\n",
            "Result: I've chosen **Dialogflow** as the platform and will define the scope as **answering FAQs about a fictional online bookstore called \"Bookworm Haven.\"** The chatbot will handle questions about store hours, shipping policies, and available payment methods.\n",
            "\n",
            "AIMessage: Executed: 2.  **Design the Conversation Flow:** Map out the basic conversation flow.  Think about the questions users might ask and the corresponding answers your chatbot should provide. Create a list of intents (what the user *wants* to do) and entities (the *details* the user provides).\n",
            "Result: Okay, here's a basic conversation flow design for a hypothetical chatbot focused on helping users find information about different types of dogs:\n",
            "\n",
            "**Intents:**\n",
            "\n",
            "*   **Greet:** User greets the chatbot (e.g., \"Hello,\" \"Hi,\" \"Good morning\").\n",
            "*   **Dog_Breed_Info:** User wants information about a specific dog breed (e.g., \"Tell me about Golden Retrievers,\" \"What is a German Shepherd like?\").\n",
            "*   **Compare_Breeds:** User wants to compare two or more dog breeds (e.g., \"Compare a Poodle and a Labrador,\" \"What are the differences between a Bulldog and a Pug?\").\n",
            "*   **Recommend_Breed:** User wants a dog breed recommendation based on their lifestyle, preferences, or needs (e.g., \"What's a good dog for a family with kids?\", \"I need a low-energy dog for an apartment,\" \"Recommend a dog for someone with allergies.\").\n",
            "*   **General_Dog_Info:** User asks general questions about dogs (e.g., \"How much exercise do dogs need?\", \"What should I feed my dog?\").\n",
            "*   **Goodbye:** User ends the conversation (e.g., \"Goodbye,\" \"Thanks,\" \"Bye\").\n",
            "*   **Help:** User asks for help or clarification on how to use the chatbot (e.g., \"What can you do?\", \"How do I ask you about dog breeds?\").\n",
            "\n",
            "**Entities:**\n",
            "\n",
            "*   **Dog_Breed:** (e.g., \"Golden Retriever,\" \"German Shepherd,\" \"Poodle,\" \"Bulldog,\" \"Pug,\" \"Labrador\")\n",
            "*   **Lifestyle_Factor:** (e.g., \"Family with kids,\" \"Apartment living,\" \"Allergies,\" \"Low-energy,\" \"High-energy\")\n",
            "*   **Characteristic:** (e.g., \"Size\", \"Grooming needs\", \"Energy level\", \"Temperament\", \"Trainability\", \"Lifespan\")\n",
            "\n",
            "**Basic Conversation Flow Example:**\n",
            "\n",
            "1.  **User:** \"Hi\"\n",
            "2.  **Chatbot:** \"Hello! I can help you find information about different dog breeds. What are you interested in learning today?\" (Intent: Greet, Hinting at Capabilities)\n",
            "3.  **User:** \"Tell me about Golden Retrievers\" (Intent: Dog_Breed_Info, Entity: Dog_Breed = \"Golden Retriever\")\n",
            "4.  **Chatbot:** \"Golden Retrievers are known for being friendly, intelligent, and devoted. They are a great family dog and require a lot of exercise. Would you like to know more about their grooming needs, temperament, or anything else?\"\n",
            "5.  **User:** \"What's a good dog for someone with allergies?\" (Intent: Recommend_Breed, Entity: Lifestyle_Factor = \"Allergies\")\n",
            "6.  **Chatbot:** \"Some breeds are considered more hypoallergenic than others, such as Poodles, Bichon Frise, and Portuguese Water Dogs. However, no dog is 100% hypoallergenic. Would you like to learn more about any of these breeds?\"\n",
            "7.  **User:** \"Compare a Poodle and a Labrador\" (Intent: Compare_Breeds, Entity: Dog_Breed = \"Poodle\", Dog_Breed = \"Labrador\")\n",
            "8.  **Chatbot:** \"Sure! Poodles are generally considered more hypoallergenic and require professional grooming, while Labradors shed more and are known for their love of retrieving. Labradors are typically higher energy than poodles. Would you like a more detailed comparison?\"\n",
            "\n",
            "This is a simplified version. A real chatbot would require much more detailed flows, error handling, and ways to handle unexpected user input.\n",
            "\n",
            "AIMessage: Executed: 3.  **Implement & Test:**  Use the chosen platform to implement your conversation flow. Train the chatbot with sample phrases related to each intent. Thoroughly test the chatbot with different user inputs to identify areas for improvement and refine its responses.\n",
            "Result: Okay, let's assume I've chosen Dialogflow as my platform.\n",
            "\n",
            "**Implementation & Testing Process:**\n",
            "\n",
            "1.  **Dialogflow Setup:** Created a new Dialogflow agent.\n",
            "2.  **Intent Creation & Training:**\n",
            "    *   Created intents for:\n",
            "        *   `Greetings` (e.g., \"Hi\", \"Hello\", \"Good morning\")\n",
            "        *   `BookAppointment` (e.g., \"I want to book an appointment\", \"Schedule a time\")\n",
            "        *   `CancelAppointment` (e.g., \"I need to cancel my appointment\", \"Remove my booking\")\n",
            "        *   `CheckAvailability` (e.g., \"Are there any slots open?\", \"What's available?\")\n",
            "        *   `GetLocation` (e.g., \"Where are you located?\", \"Address?\")\n",
            "        *   `Default Fallback Intent` (for handling unknown inputs)\n",
            "    *   Added training phrases to each intent (around 10-20 for each).\n",
            "    *   Configured parameters for `BookAppointment` (e.g., `date`, `time`, `service`).\n",
            "3.  **Response Configuration:**  Defined responses for each intent.  For example:\n",
            "    *   `Greetings`: \"Hello! How can I help you today?\"\n",
            "    *   `BookAppointment`: \"What date and time would you like to book your appointment?\" (collecting parameters)\n",
            "    *   `CancelAppointment`: \"Could you please provide your appointment details so I can cancel it for you?\"\n",
            "    *   `CheckAvailability`: \"Please specify the date you're looking for.\"\n",
            "    *   `GetLocation`: \"We are located at [Your Clinic Address].\"\n",
            "    *   `Default Fallback Intent`: \"I'm sorry, I didn't understand. Could you please rephrase?\"\n",
            "4.  **Testing:** Used the Dialogflow simulator and real-world testing with various inputs:\n",
            "    *   **Positive Tests:** Tested with phrases directly related to training data.  Verified correct intent matching and response.\n",
            "    *   **Negative Tests:** Intentionally used misspelled words, incomplete sentences, and ambiguous phrasing to test robustness.\n",
            "    *   **Edge Cases:**  Tried phrases that were similar to multiple intents to see if the intent matching was accurate.\n",
            "    *   **Parameter Extraction:** Tested different date and time formats to ensure parameter extraction worked correctly.\n",
            "    *   **Conversation Flow:** Tested multi-turn conversations (e.g., booking an appointment and then asking to change it).\n",
            "\n",
            "**Brief Result:**\n",
            "\n",
            "The initial implementation successfully identifies basic intents like greetings and simple appointment booking requests.  However, testing revealed the following:\n",
            "\n",
            "*   **Limitations with Ambiguity:** The chatbot struggles with ambiguous requests or phrases that are only slightly different from the training data.\n",
            "*   **Parameter Extraction Issues:**  Parameter extraction for date and time can be unreliable with certain input formats.\n",
            "*   **Lack of Context:** The chatbot forgets the context of the conversation in multi-turn interactions. It needs to be improved to remember previous answers and user information.\n",
            "*   **Fallback Handling:**  The fallback intent is triggered frequently, indicating a need for more training data and potentially additional intents.\n",
            "\n",
            "**Next Steps (Based on Testing):**\n",
            "\n",
            "*   Add more diverse training phrases, including variations and common misspellings.\n",
            "*   Improve parameter extraction using entities and regular expressions.\n",
            "*   Implement context management to maintain the conversation flow.\n",
            "*   Refine the fallback intent response to be more helpful.\n",
            "*   Consider adding more specific intents based on observed user input.\n"
          ]
        }
      ],
      "source": [
        "def execute_step(state: PlanningState):\n",
        "   \"\"\"Executes the current step in the plan\"\"\"\n",
        "   if state[\"current_step\"] >= len(state[\"plan\"]):\n",
        "       final_summary = \"\\n\".join(state[\"step_results\"])\n",
        "       return {\n",
        "           \"messages\": [AIMessage(content=f\"Plan completed. Results:\\n{final_summary}\")],\n",
        "           \"current_step\": state[\"current_step\"]\n",
        "       }\n",
        "\n",
        "   current_step = state[\"plan\"][state[\"current_step\"]]\n",
        "\n",
        "   # Execute current step\n",
        "   prompt = f\"Execute this step: {current_step}\\nProvide a brief result.\"\n",
        "   result = llm.invoke(prompt)\n",
        "\n",
        "   return {\n",
        "       \"messages\": [AIMessage(content=f\"Executed: {current_step}\\nResult: {result.content}\")],\n",
        "       \"current_step\": state[\"current_step\"] + 1,\n",
        "       \"step_results\": state[\"step_results\"] + [f\"Step {state['current_step'] + 1}: {result.content}\"]\n",
        "   }\n",
        "\n",
        "# Create planning agent workflow\n",
        "planning_graph = StateGraph(PlanningState)\n",
        "planning_graph.add_node(\"planner\", planning_agent)\n",
        "planning_graph.add_node(\"executor\", execute_step)\n",
        "\n",
        "planning_graph.set_entry_point(\"planner\")\n",
        "planning_graph.add_edge(\"planner\", \"executor\")\n",
        "\n",
        "# Add loop for executing all steps\n",
        "def should_continue(state: PlanningState):\n",
        "   if state[\"current_step\"] >= len(state[\"plan\"]):\n",
        "       return END\n",
        "   return \"executor\"\n",
        "\n",
        "planning_graph.add_conditional_edges(\"executor\", should_continue, {\"executor\": \"executor\", END: END})\n",
        "\n",
        "# Compile and test\n",
        "planning_compiled = planning_graph.compile()\n",
        "\n",
        "# Test planning agent\n",
        "result = planning_compiled.invoke({\n",
        "   \"messages\": [HumanMessage(content=\"Plan and execute: Create a simple chatbot\")],\n",
        "   \"plan\": [],\n",
        "   \"current_step\": 0,\n",
        "   \"step_results\": []\n",
        "})\n",
        "\n",
        "print(\"Planning Agent Results:\")\n",
        "for msg in result[\"messages\"]:\n",
        "   print(f\"\\n{msg.__class__.__name__}: {msg.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbKwswSpFiI_"
      },
      "source": [
        "## âœ… Summary and Testing\n",
        "\n",
        "To wrap up, we'll build a **simple test dashboard** to demonstrate and visualize the behavior of all agent patterns implemented using LangGraph:\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ” Agent Pattern Overview:\n",
        "\n",
        "1. **ðŸ§  Memory-Based Agent**  \n",
        "   - Remembers past interactions  \n",
        "   - Generates context-aware responses using stored conversation history\n",
        "\n",
        "2. **ðŸ› ï¸ Tool-Using Agent**  \n",
        "   - Integrates external tools (e.g., Wikipedia API)  \n",
        "   - Follows Thought â†’ Action â†’ Observation reasoning\n",
        "\n",
        "3. **ðŸ¤ Multi-Agent Collaboration**  \n",
        "   - Multiple agents with specialized roles  \n",
        "   - Work together by sharing state and delegating tasks\n",
        "\n",
        "4. **ðŸ§­ Planning Agent**  \n",
        "   - Decomposes tasks into steps  \n",
        "   - Executes them sequentially toward a goal\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ“Š Test Dashboard Features:\n",
        "\n",
        "- A unified interface to:\n",
        "  - Send prompts to any agent type\n",
        "  - Trace execution flow\n",
        "  - Visualize intermediate states and agent transitions\n",
        "- Useful for **testing**, **debugging**, and **demoing agent behaviors**\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸš§ Next Steps: CrewAI Version\n",
        "\n",
        "For the **CrewAI implementation**, the same patterns will be reconstructed using **CrewAIâ€™s agent-role-task architecture**, which follows a different collaboration and orchestration strategy than LangGraph.\n",
        "\n",
        "---\n",
        "\n",
        "âœ… **Conclusion:**  \n",
        "Youâ€™ve now implemented and tested a variety of powerful agent patterns using LangGraphâ€”each designed for real-world tasks, traceability, and modular extensibility.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a simple memory-based agent\n",
        "from langgraph.graph import StateGraph, END\n",
        "from typing import Annotated, TypedDict\n",
        "import operator\n",
        "\n",
        "# Define the state for our agent\n",
        "class AgentState(TypedDict):\n",
        "   messages: Annotated[list, operator.add]\n",
        "\n",
        "# Create a simple agent that remembers context\n",
        "def memory_agent(state: AgentState):\n",
        "   # Get the last message\n",
        "   last_message = state[\"messages\"][-1]\n",
        "\n",
        "   # Convert messages to string format for context\n",
        "   context_str = \"\\n\".join([f\"{msg.__class__.__name__}: {msg.content}\" for msg in state[\"messages\"]])\n",
        "\n",
        "   # Generate a response based on all previous messages\n",
        "   prompt = f\"Context of conversation:\\n{context_str}\\n\\nCurrent message: {last_message.content}\\n\\nResponse:\"\n",
        "   response = llm.invoke(prompt)\n",
        "\n",
        "   return {\"messages\": [AIMessage(content=response.content)]}\n",
        "\n",
        "# Create the graph\n",
        "memory_graph = StateGraph(AgentState)\n",
        "memory_graph.add_node(\"agent\", memory_agent)\n",
        "memory_graph.set_entry_point(\"agent\")\n",
        "memory_graph.add_edge(\"agent\", END)\n",
        "\n",
        "# Compile with checkpointer for memory\n",
        "memory_checkpointer = MemorySaver()\n",
        "memory_compiled = memory_graph.compile(checkpointer=memory_checkpointer)\n",
        "\n",
        "# Test the memory agent\n",
        "config = {\"configurable\": {\"thread_id\": \"test_thread\"}}\n",
        "result = memory_compiled.invoke(\n",
        "   {\"messages\": [HumanMessage(content=\"My favorite color is blue\")]},\n",
        "   config=config\n",
        ")\n",
        "print(\"Agent:\", result[\"messages\"][-1].content)\n",
        "\n",
        "# Test that it remembers\n",
        "result2 = memory_compiled.invoke(\n",
        "   {\"messages\": [HumanMessage(content=\"What's my favorite color?\")]},\n",
        "   config=config\n",
        ")\n",
        "print(\"Agent:\", result2[\"messages\"][-1].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r411LR3tkxqC",
        "outputId": "c34836ce-3192-461a-a95f-4b2d2f2ed482"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent: That's a great choice! Blue is a very popular and versatile color. What do you like about it?\n",
            "Agent: You told me earlier that your favorite color is blue.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a test dashboard to demonstrate all patterns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "# Create visualization of agent patterns\n",
        "fig = plt.figure(figsize=(15, 10))\n",
        "gs = gridspec.GridSpec(2, 2, figure=fig)\n",
        "\n",
        "# Test all patterns and visualize\n",
        "patterns = {\n",
        "   \"Memory Agent\": memory_compiled,\n",
        "   \"Tool Agent\": tool_compiled,\n",
        "   \"Multi-Agent\": multi_agent,\n",
        "   \"Planning Agent\": planning_compiled\n",
        "}\n",
        "\n",
        "test_queries = {\n",
        "   \"Memory Agent\": [\"My name is Alice\", \"What's my name?\"],\n",
        "   \"Tool Agent\": [\"search for Python programming\"],\n",
        "   \"Multi-Agent\": [\"research about machine learning\"],\n",
        "   \"Planning Agent\": [\"Plan: write a blog post about AI\"]\n",
        "}\n",
        "\n",
        "results = {}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "dvhRzlcsklzG",
        "outputId": "1301010c-2673-4ca0-b744-83858f15701c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1000 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "tDi6HvD9FgzG",
        "outputId": "7bac95cd-cfca-4b06-b992-ba2119c6ca8c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== LangGraph Agent Patterns Summary ===\n",
            "\n",
            "Memory Agent:\n",
            "  Response 1: This is a tricky one. The best response depends on what you're trying to achieve with the chatbot. Here are a few options, ranging from basic to more sophisticated:\n",
            "\n",
            "**1. Basic Acknowledgement (If you...\n",
            "  Response 2: This is another tricky situation where understanding context is key. Here's a breakdown of why the user might be asking and how to respond:\n",
            "\n",
            "**Possible Reasons for the Question:**\n",
            "\n",
            "*   **Testing the C...\n",
            "\n",
            "Tool Agent:\n",
            "  Response 1: I searched for 'Python programming' and found:\n",
            "\n",
            "Page: Python (programming language)\n",
            "Summary: Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readabi...\n",
            "\n",
            "Multi-Agent:\n",
            "  Response 1: Research findings: Page: Machine learning\n",
            "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can lear...\n",
            "  Response 2: Machine learning (ML) is a branch of artificial intelligence focused on developing statistical algorithms that learn from data and generalize to new data without explicit instructions. Deep learning, ...\n",
            "\n",
            "Planning Agent:\n",
            "  Response 1: Created plan:\n",
            "Here's a breakdown of planning a blog post about AI into 3 simple steps:\n",
            "\n",
            "1.  **Choose a Specific Angle & Define Your Audience:**  Instead of just \"AI,\" narrow down your topic (e.g., \"AI...\n",
            "  Response 2: Executed: 1.  **Choose a Specific Angle & Define Your Audience:**  Instead of just \"AI,\" narrow down your topic (e.g., \"AI in Healthcare,\" \"Ethical Considerations of AI,\" or \"AI for Beginners\").  Also...\n",
            "  Response 3: Executed: 2.  **Outline Key Points & Gather Information:**  Brainstorm the main ideas you want to cover related to your chosen angle.  Do some research (articles, reports, examples) to support your po...\n",
            "  Response 4: Executed: 3.  **Write a Draft & Add Visuals (Optional):**  Based on your outline, write a first draft focusing on clear and concise language. Don't worry about perfection at this stage. Consider addin...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Test each pattern\n",
        "for pattern_name, agent in patterns.items():\n",
        "   if pattern_name == \"Memory Agent\":\n",
        "       config = {\"configurable\": {\"thread_id\": \"demo_thread\"}}\n",
        "       result1 = agent.invoke({\"messages\": [HumanMessage(content=test_queries[pattern_name][0])]}, config=config)\n",
        "       result2 = agent.invoke({\"messages\": [HumanMessage(content=test_queries[pattern_name][1])]}, config=config)\n",
        "       results[pattern_name] = [result1[\"messages\"][-1].content, result2[\"messages\"][-1].content]\n",
        "   else:\n",
        "       if pattern_name == \"Multi-Agent\":\n",
        "           result = agent.invoke({\n",
        "               \"messages\": [HumanMessage(content=test_queries[pattern_name][0])],\n",
        "               \"task_type\": \"research_and_write\",\n",
        "               \"current_agent\": \"researcher\",\n",
        "               \"result\": \"\"\n",
        "           })\n",
        "           results[pattern_name] = [msg.content for msg in result[\"messages\"] if isinstance(msg, AIMessage)]\n",
        "       elif pattern_name == \"Planning Agent\":\n",
        "           result = agent.invoke({\n",
        "               \"messages\": [HumanMessage(content=test_queries[pattern_name][0])],\n",
        "               \"plan\": [],\n",
        "               \"current_step\": 0,\n",
        "               \"step_results\": []\n",
        "           })\n",
        "           results[pattern_name] = [msg.content for msg in result[\"messages\"] if isinstance(msg, AIMessage)]\n",
        "       else:\n",
        "           result = agent.invoke({\"messages\": [HumanMessage(content=test_queries[pattern_name][0])]})\n",
        "           results[pattern_name] = [result[\"messages\"][-1].content]\n",
        "\n",
        "# Display results\n",
        "for i, (pattern_name, pattern_results) in enumerate(results.items()):\n",
        "   ax = fig.add_subplot(gs[i // 2, i % 2])\n",
        "   ax.text(0.5, 0.9, pattern_name, ha='center', va='center', fontsize=14, fontweight='bold')\n",
        "\n",
        "   result_text = \"\\n\".join([f\"Response: {r[:100]}...\" if len(r) > 100 else f\"Response: {r}\" for r in pattern_results])\n",
        "   ax.text(0.5, 0.5, result_text, ha='center', va='center', fontsize=10, wrap=True)\n",
        "   ax.set_xlim(0, 1)\n",
        "   ax.set_ylim(0, 1)\n",
        "   ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print summary\n",
        "print(\"\\n=== LangGraph Agent Patterns Summary ===\")\n",
        "for pattern_name, pattern_results in results.items():\n",
        "   print(f\"\\n{pattern_name}:\")\n",
        "   for j, result in enumerate(pattern_results):\n",
        "       print(f\"  Response {j+1}: {result[:200]}...\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}